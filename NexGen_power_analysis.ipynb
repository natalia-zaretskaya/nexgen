{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04639387669523733\n"
     ]
    }
   ],
   "source": [
    "# estimate CNR of the auditory claustrum based on the CNR of the cortical regions and the visual clausru\n",
    "visual_cortex = (0.54186845 + 0.65284463)/2\n",
    "visual_claustrum = 0.07299358\n",
    "auditory_cortex = 0.37967292\n",
    "auditory_claustrum = auditory_cortex*visual_claustrum/visual_cortex\n",
    "print(auditory_claustrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "roi = ['visual \\n cortex', 'auditory \\n cortex', 'visual \\n claustrum', 'auditory \\n claustrum']\n",
    "plt.bar(roi, [visual_cortex, auditory_cortex, visual_claustrum, auditory_claustrum], color='black', edgecolor='black', capsize=5)\n",
    "plt.xlabel('Region of Interest')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('CNR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4309.069888194205\n",
      "1741.0154354165134\n"
     ]
    }
   ],
   "source": [
    "# power analysis at the single-subject level (n samples/n volumes need to detect significan voxels)\n",
    "from statsmodels.stats.power import ttest_power, tt_ind_solve_power\n",
    "ratio=2 # ratio is 2, because we can boost power by comparing auditory to visual+basline\n",
    "# (since we have all 3 conditions in one experiment)\n",
    "n_samples_A = tt_ind_solve_power(effect_size=auditory_claustrum, alpha=0.05, power=0.8, ratio=ratio, alternative='larger')\n",
    "n_samples_V = tt_ind_solve_power(effect_size=visual_claustrum, alpha=0.05, power=0.8, ratio=ratio, alternative='larger')\n",
    "print(n_samples_A)\n",
    "print(n_samples_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.181783146990343\n",
      "2.9016923923608555\n"
     ]
    }
   ],
   "source": [
    "# n scanning hours (note: n_samples total = n_samples_A+n_samples_V+n_samples_B)\n",
    "scanning_time_hours_A = (n_samples_A+n_samples_A*ratio)*2/60/60\n",
    "scanning_time_hours_V = (n_samples_V+n_samples_V*ratio)*2/60/60\n",
    "print(scanning_time_hours_A)\n",
    "print(scanning_time_hours_V)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
